========================================================================================
Iteration : 0

parameters = logreg defaults
		  
		  
best params:
n/a
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
          0.84934 ± 0.00733 accuracy  
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.853719420868697


classification report below
              precision    recall  f1-score   support

           0       0.88      0.94      0.91      4781
           1       0.70      0.50      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.75      6009
weighted avg       0.84      0.85      0.84      6009


Summary:

========================================================================================
Iteration : 1 + 2

parameters = params = {}
params['ct__subpipe_num__num_impute__strategy'] = ['mean','median']
params['logreg_basic__penalty'] = ['l1', 'l2','none'] 
params['logreg_basic__max_iter'] = [100,200,300,400,500,600]
params['logreg_basic__C'] = [1, 0.1, 0.01, 0.001, 0.0001]
		  
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'mean',
 'logreg_basic__C': 1,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'none'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            0.85017 ± 0.00704 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.8535530038275919


classification report below
              precision    recall  f1-score   support

           0       0.88      0.94      0.91      4781
           1       0.70      0.50      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.75      6009
weighted avg       0.84      0.85      0.84      6009


Summary: will force median for next run just to see result and will record that here too. Not worth giving to next iteration


CV Results for `gs_dtc_model` model:
            0.84978 ± 0.00753 accuracy
gs.best_estimator_.score(X_valid, y_valid)
			0.854052254950907
{'ct__subpipe_num__num_impute__strategy': 'median',
 'logreg_basic__C': 0.01,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'l2'}
 
 median got completely diffrent params for this score. Will gs this later. Running with mean for now
========================================================================================
Iteration : 3

parameters = 
params['ct__subpipe_num__num_impute__strategy'] = ['mean']
params['logreg_basic__penalty'] = ['l1', 'l2','none'] 
params['logreg_basic__max_iter'] = [100,150,200]
params['logreg_basic__C'] = [1, 0.1, 10]		  
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'mean',
 'logreg_basic__C': 1,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'none'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
             0.85017 ± 0.00704 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.8535530038275919


classification report below
              precision    recall  f1-score   support

           0       0.88      0.94      0.91      4781
           1       0.70      0.50      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.75      6009
weighted avg       0.84      0.85      0.84      6009


Summary: well this is dead end for mean in imputing mean. Will continue to tune imputing with median

========================================================================================
Iteration : 4

parameters = 
params['ct__subpipe_num__num_impute__strategy'] = ['median']
params['logreg_basic__penalty'] = ['l1', 'l2','none'] 
params['logreg_basic__max_iter'] = [100,150,200]
params['logreg_basic__C'] = [1, 0.1, 0.01, 0.001]
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'median',
 'logreg_basic__C': 0.01,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'l2'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
             0.84978 ± 0.00753 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.854052254950907


classification report below
              precision    recall  f1-score   support

           0       0.88      0.95      0.91      4781
           1       0.71      0.49      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.74      6009
weighted avg       0.84      0.85      0.84      6009


Summary:
idk what i expected lmao same as before. will just try to tune c since rest seem to be close to default

========================================================================================
Iteration : 5

parameters = 
params['ct__subpipe_num__num_impute__strategy'] = ['median']
params['logreg_basic__penalty'] = ['l2'] 
params['logreg_basic__max_iter'] = [100]
params['logreg_basic__C'] = [1, 0.05, 0.1, 0.15]
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'median',
 'logreg_basic__C': 0.05,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'l2'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            0.84956 ± 0.00740 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.8533865867864869


classification report below
              precision    recall  f1-score   support

           0       0.88      0.94      0.91      4781
           1       0.70      0.50      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.75      6009
weighted avg       0.84      0.85      0.84      6009


Summary: hmm. ever so slightly worse. will try one more time to hone in, if worse again will go back to using iteration 4

========================================================================================
Iteration : 6

parameters = 
params['ct__subpipe_num__num_impute__strategy'] = ['median']
params['logreg_basic__penalty'] = ['l2'] 
params['logreg_basic__max_iter'] = [100]
params['logreg_basic__C'] = [0.025, 0.05, 0.075, 0.1]		  
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'median',
 'logreg_basic__C': 0.025,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'l2'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            0.84967 ± 0.00763 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.8527209186220669


classification report below
              precision    recall  f1-score   support

           0       0.88      0.95      0.91      4781
           1       0.70      0.49      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.74      6009
weighted avg       0.84      0.85      0.84      6009


Summary: will try 1 more time. but i think this is a dead end

========================================================================================
Iteration : 7

parameters = 
params['ct__subpipe_num__num_impute__strategy'] = ['median']
params['logreg_basic__penalty'] = ['l2'] 
params['logreg_basic__max_iter'] = [100]
params['logreg_basic__C'] = [0.0125, 0.025, 0.0375]		  
		  
best params:
{'ct__subpipe_num__num_impute__strategy': 'median',
 'logreg_basic__C': 0.0375,
 'logreg_basic__max_iter': 100,
 'logreg_basic__penalty': 'l2'}
 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            0.84967 ± 0.00744 accuracy
		  
gs.best_estimator_.score(X_valid, y_valid)
			0.8528873356631719


classification report below
             precision    recall  f1-score   support

           0       0.88      0.95      0.91      4781
           1       0.70      0.49      0.58      1228

    accuracy                           0.85      6009
   macro avg       0.79      0.72      0.74      6009
weighted avg       0.84      0.85      0.84      6009


Summary: interesting, the cross val score is same with a small change in +-,
	score on validation data got better. dang. i play gatcha games, we hit those 1 more go 

========================================================================================
Iteration : 

parameters = 
		  
		  
best params:

 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            
		  
gs.best_estimator_.score(X_valid, y_valid)
			


classification report below



Summary:
========================================================================================
Template
========================================================================================
Iteration : 

parameters = 
		  
		  
best params:

 
		  
gs_pipe.print_cv_summary()		  
	CV Results for `gs_dtc_model` model:
            
		  
gs.best_estimator_.score(X_valid, y_valid)
			


classification report below



Summary:
